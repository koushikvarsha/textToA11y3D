# -*- coding: utf-8 -*-
"""textToA11y3D

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WNCYtbpMO6oIs6SjYiL0339KUr5m6FL7
"""

!pip install -q git+https://github.com/openai/shap-e.git
# !pip install -q pytorch3d
# pytorch3d often fails to install directly in Colab due to binary compatibility issues with PyTorch and CUDA
!pip install -q Pillow
!pip install ipywidgets
!pip install py3Dmol

# Imports
import os
import torch
import py3Dmol
from PIL import Image
import ipywidgets as widgets
from IPython.display import display, Image as IPyImage, clear_output
from shap_e.diffusion.sample import sample_latents
from shap_e.diffusion.gaussian_diffusion import diffusion_from_config
from shap_e.models.download import load_model, load_config
from shap_e.util.notebooks import create_pan_cameras, decode_latent_mesh, decode_latent_images
from google.colab import files

# Create output folders
os.makedirs("static", exist_ok=True) #static is used for preview renderings
os.makedirs("output", exist_ok=True) #output is used for final renderings

# .OBJ preview
def show_obj_model(file_path):
    with open(file_path, 'r') as f:
        obj_data = f.read()
    view = py3Dmol.view(width=400, height=400)
    view.addModel(obj_data, "obj")
    view.setStyle({'mesh': {'color': 'lightblue'}})
    view.zoomTo()
    return view.show()

# Load models
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
xm = load_model('transmitter', device=device)
model = load_model('text300M', device=device)
diffusion = diffusion_from_config(load_config('diffusion'))

# Updated Shap-E
def generate_shape(prompt, guidance, karras_steps, batch_size, file_type):
  latents = sample_latents(
      batch_size=batch_size,
      model=model,
      diffusion=diffusion,
      guidance_scale=guidance,
      model_kwargs=dict(texts=[prompt] * batch_size),
      progress=True,
      clip_denoised=True,
      use_fp16=True,
      use_karras=True,
      karras_steps=karras_steps,
      sigma_min=1e-3,
      sigma_max=160,
      s_churn=0,
    )
  t = decode_latent_mesh(xm, latents[0]).tri_mesh()
  filename = f"{prompt.replace(' ', '_')}{file_type}"
  output_path = f"output/{filename}"
  if file_type == '.obj':
    with open(output_path, 'w') as f:
      t.write_obj(f)
  elif file_type == '.ply':
    with open(output_path, 'wb') as f:
      t.write_ply(f)
  else:
    raise ValueError("Unsupported file type selected.")
  return output_path

def generate_preview(prompt, guidance, karras_steps, batch_size):
    # Generate latents
    latents = sample_latents(
        batch_size=batch_size,
        model=model,
        diffusion=diffusion,
        guidance_scale=guidance,
        model_kwargs=dict(texts=[prompt] * batch_size),
        progress=True,
        clip_denoised=True,
        use_fp16=True,
        use_karras=True,
        karras_steps=karras_steps,
        sigma_min=1e-3,
        sigma_max=160,
        s_churn=0,
    )
    # Create 64 camera views around the object
    cameras = create_pan_cameras(64, device)
    # Decode to image(s)
    images = decode_latent_images(xm, latents[0], cameras, rendering_mode="nerf")
    # Save first image only (just like before)
    img_path = f"static/{prompt.replace(' ', '_')}_preview.png"
    images[0].save(img_path)
    return img_path

# Define GUI
# Title
title = widgets.Label("Shap-E's Text to 3D Generator")

# Input box
prompt_input = widgets.Text(
    description='Prompt:',
    placeholder='e.g. a cat with a hat'
)

# Prompt history dropdown
prompt_history_dropdown = widgets.Dropdown(
    options=[""],
    description='History:',
    ayout=widgets.Layout(width='50%')
)

# Guidance slider
guidance_slider = widgets.FloatSlider(
    value=8, min=1.0, max=15, step=0.5,
    description='Guidance:',
    continuous_update=False
)

# Karras slider
karras_slider = widgets.IntSlider(
    value=40, min=16, max=64, step=8,
    description='Karras Steps:',
    continuous_update=False
)

# Batch size slider
batch_slider = widgets.IntSlider(
    value=1, min=1, max=4, step=1,
    description='Batch Size:',
    continuous_update=False
)

# File type dropdown
file_type_dropdown = widgets.Dropdown(
    options=['.obj', '.ply'],
    value='.obj',
    description='File Type'
)

# Buttons
clear_history_button = widgets.Button(description="Clear History")
preview_button = widgets.Button(description="Preview")
generate_button = widgets.Button(description="Generate")

# Output Display
output_area = widgets.Output()

# Callbacks
prompt_history = {}

def on_preview_clicked(b):
  prompt = prompt_input.value
  guidance = guidance_slider.value
  karras = karras_slider.value
  batch = batch_slider.value
  file_type = file_type_dropdown.value
  if prompt and prompt not in prompt_history:
    prompt_history[prompt] = (guidance, karras, batch, file_type)
    prompt_history_dropdown.options = list(prompt_history.keys())
    prompt_history_dropdown.value = prompt
  with output_area:
    clear_output()
    print("Generating preview...")
    img_path = generate_preview(prompt, guidance, karras, batch)
    display(IPyImage(filename=img_path))

def on_generate_clicked(b):
  prompt = prompt_input.value
  guidance = guidance_slider.value
  karras = karras_slider.value
  batch = batch_slider.value
  file_type = file_type_dropdown.value
  if prompt and prompt not in prompt_history:
    prompt_history[prompt] = (guidance, karras, batch, file_type)
    prompt_history_dropdown.options = list(prompt_history.keys())
    prompt_history_dropdown.value = prompt
  with output_area:
    clear_output()
    print(f"Generating {file_type.upper()} file...")
    obj_path = generate_shape(prompt, guidance, karras, batch, file_type)
    print(f"Generated: {obj_path}")
    if file_type == '.obj':
      show_obj_model(obj_path)
    elif file_type == '.glb':
      print(".GLB file generated. Preview not supported in current viewer.")
    elif file_type == '.ply':
      print(".PLY file generated. Preview not supported in current viewer.")
    files.download(obj_path)

def on_history_selected(change):
  selected = change['new']
  if selected and selected in prompt_history:
    prompt_input.value = selected
    guidance, karras, batch, file_type = prompt_history[selected]
    guidance_slider.value = guidance
    karras_slider.value = karras
    batch_slider.value = batch
    file_type_dropdown.value = file_type

def on_clear_history_clicked(b):
  prompt_history.clear()
  prompt_history_dropdown.options = []
  prompt_input.value = ""
  guidance_slider.value = 8
  karras_slider.value = 40
  batch_slider.value = 1
  file_type_dropdown.value = '.obj'
  with output_area:
    clear_output()
    print("Prompt history cleared.")

prompt_history_dropdown.observe(on_history_selected, names='value')

# Attach callbacks
clear_history_button.on_click(on_clear_history_clicked)
preview_button.on_click(on_preview_clicked)
generate_button.on_click(on_generate_clicked)

# Build and display the UI
ui = widgets.VBox([
    title,
    prompt_input,
    prompt_history_dropdown,
    widgets.HBox([clear_history_button]),
    guidance_slider,
    karras_slider,
    batch_slider,
    file_type_dropdown,
    widgets.HBox([preview_button, generate_button]),
    output_area
])

display(ui)